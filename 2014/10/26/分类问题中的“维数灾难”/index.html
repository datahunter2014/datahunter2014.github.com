<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>分类问题中的“维数灾难” | datahunter</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在看机器学习的论文时，经常会看到有作者提到“curse of dimensionality”，中文译为“维数灾难”，这到底是一个什么样的“灾难”？本文将通过一个例子来介绍这令人讨厌的“curse of dimensionality”以及它在分类问题中的重要性。">
<meta property="og:type" content="article">
<meta property="og:title" content="分类问题中的“维数灾难”">
<meta property="og:url" content="http://yoursite.com/2014/10/26/分类问题中的“维数灾难”/">
<meta property="og:site_name" content="datahunter">
<meta property="og:description" content="在看机器学习的论文时，经常会看到有作者提到“curse of dimensionality”，中文译为“维数灾难”，这到底是一个什么样的“灾难”？本文将通过一个例子来介绍这令人讨厌的“curse of dimensionality”以及它在分类问题中的重要性。">
<meta property="og:image" content="/img/201410261.png">
<meta property="og:image" content="/img/201410262.png">
<meta property="og:image" content="/img/201410263.png">
<meta property="og:image" content="/img/201410264.png">
<meta property="og:image" content="/img/201410265.png">
<meta property="og:image" content="/img/201410266.png">
<meta property="og:image" content="/img/201410267.png">
<meta property="og:image" content="/img/201410268.png">
<meta property="og:image" content="/img/201410269.png">
<meta property="og:image" content="/img/2014102610.png">
<meta property="og:image" content="/img/2014102611.png">
<meta property="og:image" content="/img/2014102612.png">
<meta property="og:image" content="/img/2014102613.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类问题中的“维数灾难”">
<meta name="twitter:description" content="在看机器学习的论文时，经常会看到有作者提到“curse of dimensionality”，中文译为“维数灾难”，这到底是一个什么样的“灾难”？本文将通过一个例子来介绍这令人讨厌的“curse of dimensionality”以及它在分类问题中的重要性。">

  
    <link rel="alternative" href="/atom.xml" title="datahunter" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">

  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">datahunter</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">主页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="submit" value="&#xF002;" class="search-form-submit"><input type="hidden" name="q" value="site:http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-分类问题中的“维数灾难”" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/10/26/分类问题中的“维数灾难”/" class="article-date">
  <time datetime="2014-10-26T07:07:16.000Z" itemprop="datePublished">2014-10-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      分类问题中的“维数灾难”
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>　　在看机器学习的论文时，经常会看到有作者提到“curse of dimensionality”，中文译为“维数灾难”，这到底是一个什么样的“灾难”？本文将通过一个例子来介绍这令人讨厌的“curse of dimensionality”以及它在分类问题中的重要性。<br><a id="more"></a></p>
<p>　　假设现在有一组照片，每一张照片里有一只猫或者一条狗。我们希望设计一个分类器可以自动地将照片中的动物辨别开来。为了实现这个目标，首先需要考虑如何将照片中的动物的特征用数字的形式表达出来。猫与狗的最大区别是什么？有人可能首先想到猫与狗的颜色不一样，有人则可能想到猫与狗的大小不一样。假设从颜色来辨别猫与狗，可以设计三个特征：红色的平均值，绿色的平均值和蓝色的平均值，来决定照片中的动物属于哪一个类：</p>
<figure class="highlight [python]"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="input"><span class="prompt">if 0.5 * red + 0.3 * green + 0.2 * blue &gt;</span> <span class="number">0</span>.<span class="number">6</span><span class="symbol">:</span></span></div><div class="line">    <span class="keyword">return</span> cat</div><div class="line"><span class="symbol">else:</span></div><div class="line">    <span class="keyword">return</span> dog</div><div class="line">}</div></pre></td></tr></table></figure>

<p>　　但是，仅仅通过这三个特征进行分类可能无法得到一个令人满意的结果。因此，可以再增加一些特征：大小，纹理等。也许增加特征之后，分类的结果会有所提高。但是，特征是不是越多越好？</p>
<p><img src="/img/201410261.png"></p>
<center>图1</center> 

<p>　　从图1可以看到分类器的性能随着特征个数的变化不断增加，过了某一个值后，性能不升反降。这种现象称为“维数灾难”。继续之前的例子。假设地球上猫和狗的数量是无限的。由于有限的时间和计算能力，我们仅仅选取了10张照片作为训练样本。我们的目的是基于这10张照片来训练一个线性分类器，使得这个线性分类器可以对剩余的猫或狗的照片进行正确分类。我们从只用一个特征来辨别猫和狗开始：</p>
<p><img src="/img/201410262.png"></p>
<center>图2</center>

<p>　　从图2可以看到，如果仅仅只有一个特征的话，猫和狗几乎是均匀分布在这条线段上，很难将10张照片线性分类。那么，增加一个特征后的情况会怎么样：</p>
<p><img src="/img/201410263.png"></p>
<center>图3</center>

<p>　　增加一个特征后，我们发现仍然无法找到一条直线将猫和狗分开。所以，考虑需要再增加一个特征：</p>
<p><img src="/img/201410264.png"></p>
<center>图4</center>

<p><img src="/img/201410265.png"></p>
<center>图5</center>

<p>　　此时，我们终于找到了一个平面将猫和狗分开。需要注意的是，只有一个特征时，假设特征空间是长度为5的线段，则样本密度是10//5=2。有两个特征时，特征空间大小是5*5=25，样本密度是10/25=0.4。有三个特征时，特征空间大小是5*5*5=125，样本密度是10/125=0.08。如果继续增加特征数量，样本密度会更加稀疏，也就更容易找到一个超平面将训练样本分开。因为随着特征数量趋向于无限大，样本密度非常稀疏，训练样本被分错的可能性趋向于零。当我们将高维空间的分类结果映射到低维空间时，一个严重的问题出现了：</p>
<p><img src="/img/201410266.png"></p>
<center>图6</center>

<p>　　从图6可以看到将三维特征空间映射到二维特征空间后的结果。尽管在高维特征空间时训练样本线性可分，但是映射到低维空间后，结果正好相反。事实上，增加特征数量使得高维空间线性可分，相当于在低维空间内训练一个复杂的非线性分类器。不过，这个非线性分类器太过“聪明”，仅仅学到了一些特例。如果将其用来辨别那些未曾出现在训练样本中的测试样本时，通常结果不太理想。这其实就是我们在机器学习中学过的过拟合问题。</p>
<p><img src="/img/201410267.png"></p>
<center>图7</center>

<p>　　尽管图7所示的只采用2个特征的线性分类器分错了一些训练样本，准确率似乎没有图4的高，但是，采用2个特征的线性分类器的泛化能力比采用3个特征的线性分类器要强。因为，采用2个特征的线性分类器学习到的不只是特例，而是一个整体趋势，对于那些未曾出现过的样本也可以比较好地辨别开来。换句话说，通过减少特征数量，可以避免出现过拟合问题，从而避免“维数灾难”。</p>
<p><img src="/img/201410268.png"></p>
<center>图8</center> 

<p>　　图8从另一个角度诠释了“维数灾难”。假设只有一个特征时，特征的值域是0到1，每一只猫和狗的特征值都是唯一的。如果我们希望训练样本覆盖特征值值域的20%，那么就需要猫和狗总数的20%。我们增加一个特征后，为了继续覆盖特征值值域的20%就需要猫和狗总数的45%(0.45^2=0.2)。继续增加一个特征后，需要猫和狗总数的58%(0.58^3=0.2)。随着特征数量的增加，为了覆盖特征值值域的20%，就需要更多的训练样本。如果没有足够的训练样本，就可能会出现过拟合问题。<br>　　通过上述例子，我们可以看到特征数量越多，训练样本就会越稀疏，分类器的参数估计就会越不准确，更加容易出现过拟合问题。“维数灾难”的另一个影响是训练样本的稀疏性并不是均匀分布的。处于中心位置的训练样本比四周的训练样本更加稀疏。</p>
<p><img src="/img/201410269.png"></p>
<center>图9</center> 

<p>　　假设有一个二维特征空间，如图8所示的矩形，在矩形内部有一个内切的圆形。由于越接近圆心的样本越稀疏，因此，相比于圆形内的样本，那些位于矩形四角的样本更加难以分类。那么，随着特征数量的增加，圆形的面积会不会变化呢？这里我们假设超立方体(hypercube)的边长d=1，那么计算半径为0.5的超球面(hypersphere)的体积(volume)的公式为：</p>
<p><img src="/img/2014102610.png"></p>
<center>公式1</center> 

<p><img src="/img/2014102611.png"></p>
<center>图10</center> 

<p>　　从图10可以看出随着特征数量的增加，超球面的体积逐渐减小直至趋向于零，然而超立方体的体积却不变。这个结果有点出乎意料，但部分说明了分类问题中的“维数灾难”：在高维特征空间中，大多数的训练样本位于超立方体的角落。</p>
<p><img src="/img/2014102612.png"></p>
<center>图11</center> 

<p>　　图11显示了不同维度下，样本的分布情况。在8维特征空间中，共有2^8=256个角落，而98%的样本分布在这些角落。随着维度的不断增加，公式2将趋向于0，其中dist_max和dist_min分别表示样本到中心的最大与最小距离。</p>
<p><img src="/img/2014102613.png"></p>
<center>公式2</center> 

<p>　　因此，在高维特征空间中对于样本距离的度量失去意义。由于分类器基本都依赖于如Euclidean距离，Manhattan距离等，所以在特征数量过大时，分类器的性能就会出现下降。<br>　　所以，我们如何避免“维数灾难”？图1显示了分类器的性能随着特征个数的变化不断增加，过了某一个值后，性能不升反降。这里的某一个值到底是多少呢？目前，还没有方法来确定分类问题中的这个阈值是多少，这依赖于训练样本的数量，决策边界的复杂性以及分类器的类型。理论上，如果训练样本的数量无限大，那么就不会存在“维数灾难”，我们可以采用任意多的特征来训练分类器。事实上，训练样本的数量是有限的，所以不应该采用过多的特征。此外，那些需要精确的非线性决策边界的分类器，比如neural network，knn，decision trees等的泛化能力往往并不是很好，更容易发生过拟合问题。因此，在设计这些分类器时应当慎重考虑特征的数量。相反，那些泛化能力较好的分类器，比如naive Bayesian，linear classifier等，可以适当增加特征的数量。<br>　　如果给定了N个特征，我们该如何从中选出M个最优的特征？最简单粗暴的方法是尝试所有特征的组合，从中挑出M个最优的特征。事实上，这是非常花时间的，或者说不可行的。其实，已经有许多特征选择算法(feature selection algorithms)来帮助我们确定特征的数量以及选择特征。此外，还有许多特征抽取方法(feature extraction methods)，比如PCA等。交叉验证(cross-validation)也常常被用于检测与避免过拟合问题。</p>
<h3 id="参考资料：">参考资料：</h3>
<p>[1] Vincent Spruyt. The Curse of Dimensionality in classification. Computer vision for dummies. 2014. [<a href="http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/" target="_blank" rel="external">Link</a>]</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2014/10/26/分类问题中的“维数灾难”/" data-id="fxle0fg7oa9n4u39" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </footer>
  </div>
  
    
  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/机器学习/" style="font-size: NaNpx;">机器学习</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2014/10/26/分类问题中的“维数灾难”/">分类问题中的“维数灾难”</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    <div class="widget-wrap">
	<div class="widget tag">
		<h3 class="title">Frendly Links</h3>
		<ul class="entry">
			<li><a href="http://dozycfs.farbox.com/" title="Dozycfs">Dozycfs</a></li>
			<li><a href="http://coderart.cn/" title="Dancing In The Code">Dancing In The Code</a></li>
		</ul>
	</div>
</div>
  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2014 Mark Lin<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">主页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">

  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<script src="/js/script.js" type="text/javascript"></script>


  </div>
</body>
</html>